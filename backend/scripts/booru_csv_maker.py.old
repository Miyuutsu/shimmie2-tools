from PIL import Image, UnidentifiedImageError
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from huggingface_hub import hf_hub_download
from huggingface_hub.utils import HfHubHTTPError
from io import BytesIO
from pathlib import Path
from pyvips import Image as VipsImage
from simple_parsing import field, parse_known_args
from sd_tag_editor.tag_tree_functions import flatten_tags, load_groups, GroupTree, prune
from tempfile import NamedTemporaryFile
from timm.data import create_transform, resolve_data_config
from torch import Tensor, nn
from torch.nn import functional as F
from typing import Optional, Tuple
import csv
import hashlib
import json
import numpy as np
import pandas as pd
import pyvips
import re
import sqlite3
import sys
import tempfile
import timm
import torch
import tqdm

Image.MAX_IMAGE_PIXELS = None
torch_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

MODEL_REPO_MAP = {
    "vit": "SmilingWolf/wd-vit-tagger-v3",
    "vit-large": "SmilingWolf/wd-vit-large-tagger-v3",
    "swinv2": "SmilingWolf/wd-swinv2-tagger-v3",
    "convnext": "SmilingWolf/wd-convnext-tagger-v3",
}

ALLOWED_EXTS = {".jpg", ".jpeg", ".png", ".webp"}
MD5_RE = re.compile(r"[a-fA-F0-9]{32}")

@dataclass
class ScriptOptions:
    image_or_images: str = field(default="NO_INPUT")
    batch_size: int = field(default=8)
    model: str = field(default="vit")
    gen_threshold: float = field(default=0.35)
    rating_threshold: float = field(default=0.35)
    char_threshold: float = field(default=0.75)
    subfolder: bool = field(default=False)
    shimmie: bool = field(default=False)
    no_prune: bool = field(default=False)
    posts_json: Optional[str] = field(default=None)
    threads: int = field(default=8)
    input_cache: Optional[str] = field(default=None)

@dataclass
class LabelData:
    names: list[str]
    rating: list[int]
    general: list[int]
    character: list[int]
    artist: list[int]
    copyright: list[int]

def resolve_post(image: Path, sqlite_path: Path) -> tuple[Path, dict | None]:
    conn = sqlite3.connect(sqlite_path)
    cur = conn.cursor()

    # Try MD5 from filename
    match = MD5_RE.search(image.stem)
    md5 = match.group(0).lower() if match else None
    post = None

    if cur and md5:
        cur.execute("SELECT * FROM posts WHERE md5 = ?", (md5,))
        row = cur.fetchone()
        if row:
            post = row_to_post_dict(row)

    if not post and cur:
        try:
            px_hash = compute_danbooru_pixel_hash(image)
            cur.execute("SELECT * FROM posts WHERE pixel_hash = ?", (px_hash,))
            row = cur.fetchone()
            if row:
                post = row_to_post_dict(row)
        except Exception as e:
            print(f"[WARN] Pixel hash failed for {image.name}: {e}")

    conn.close()
    return image, post


def row_to_post_dict(row: tuple) -> dict:
    return {
        "md5": row[0],
        "pixel_hash": row[1],
        "rating": row[2],
        "source": row[3],
        "general": row[4].split(",") if row[4] else [],
        "character": row[5].split(",") if row[5] else [],
        "artist": row[6].split(",") if row[6] else [],
        "series": row[7].split(",") if row[7] else [],
    }

def compute_danbooru_pixel_hash(image_path: Path) -> str:
    image = pyvips.Image.new_from_file(str(image_path), access="sequential")

    # Match Danbooru's ICC transform and color space normalization
    if image.get_typeof("icc-profile-data") != 0:
        image = image.icc_transform("srgb")
    if image.interpretation != "srgb":
        image = image.colourspace("srgb")
    if not image.hasalpha():
        image = image.addalpha()

    # Write raw P7 header
    header = (
        b"P7\n"
        + f"WIDTH {image.width}\n".encode()
        + f"HEIGHT {image.height}\n".encode()
        + f"DEPTH {image.bands}\n".encode()
        + b"MAXVAL 255\n"
        + b"TUPLTYPE RGB_ALPHA\n"
        + b"ENDHDR\n"
    )

    # Get raw RGBA pixel bytes in memory
    raw_bytes = image.write_to_memory()

    # Concatenate and hash
    buffer = header + raw_bytes
    return hashlib.md5(buffer).hexdigest()

def md5sum(path: Path) -> str:
    h = hashlib.md5()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

def pil_ensure_rgb(image: Image.Image) -> Image.Image:
    if image.mode not in ["RGB", "RGBA"]:
        image = image.convert("RGBA") if "transparency" in image.info else image.convert("RGB")
    if image.mode == "RGBA":
        canvas = Image.new("RGBA", image.size, (255, 255, 255))
        canvas.alpha_composite(image)
        image = canvas.convert("RGB")
    return image

def pil_pad_square(image: Image.Image) -> Image.Image:
    w, h = image.size
    px = max(w, h)
    canvas = Image.new("RGB", (px, px), (255, 255, 255))
    canvas.paste(image, ((px - w) // 2, (px - h) // 2))
    return canvas

def load_and_process_image(path: Path, transform) -> Optional[Tensor]:
    try:
        img = Image.open(path)
        img = pil_ensure_rgb(img)
        img = pil_pad_square(img)
        img_tensor = transform(img).unsqueeze(0)[:, [2, 1, 0]]
        return img_tensor
    except (UnidentifiedImageError, OSError):
        return None

def process_batch(batch: list[Path], transform) -> torch.Tensor:
    with ThreadPoolExecutor() as executor:
        results = list(executor.map(lambda p: load_and_process_image(p, transform), batch))
    return torch.cat([r for r in results if r is not None])

def get_tags(probs: Tensor, labels, gen_threshold, char_threshold, rating_threshold):
    probs = list(zip(labels.names, probs.numpy()))
    gen = {x[0]: x[1] for x in (probs[i] for i in labels.general) if x[1] > gen_threshold}
    char = {x[0]: x[1] for x in (probs[i] for i in labels.character) if x[1] > char_threshold}
    artist = {x[0]: x[1] for x in (probs[i] for i in labels.artist) if x[1] > char_threshold}
    series = {x[0]: x[1] for x in (probs[i] for i in labels.copyright) if x[1] > char_threshold}
    rating = {x[0]: x[1] for x in (probs[i] for i in labels.rating) if x[1] > rating_threshold}
    return char, gen, artist, series, rating

def flatten_all_tags(char, gen, artist, series, rating, group_tree, no_prune):
    pruned_gen = list(gen.items())
    if no_prune:
        pruned = pruned_gen
    else:
        pruned = flatten_tags(prune(group_tree, dict(pruned_gen)), True)
    pruned_char = [(f"character:{k}", v) for k, v in char.items()]
    pruned_artist = [(f"artist:{k}", v) for k, v in artist.items()]
    pruned_series = [(f"series:{k}", v) for k, v in series.items()]
    pruned_rating = [(k, v) for k, v in rating.items()]
    combined = pruned + pruned_char + pruned_artist + pruned_series + pruned_rating
    seen = set()
    final = []
    for tag, score in sorted(combined, key=lambda x: x[1], reverse=True):
        if tag not in seen:
            seen.add(tag)
            final.append(tag)
    return final

def main(opts: ScriptOptions):
    print("=== Tagger Run Summary ===")
    print(f"📁  Input:           {opts.image_or_images}")
    print(f"📥  Input Cache:     {opts.input_cache or 'tools/posts_cache.db'}")
    print(f"📦  Batch Size:      {opts.batch_size}")
    print(f"🧠  Model:           {opts.model}")
    print(f"✨  Gen Threshold:   {opts.gen_threshold:.2f}")
    print(f"🔞  Rating Threshold:{opts.rating_threshold:.2f}")
    print(f"👤  Char Threshold:  {opts.char_threshold:.2f}")
    print(f"🧵  Threads:         {opts.threads}")
    print(f"📂  Subfolders:      {'Yes' if opts.subfolder else 'No'}")
    print(f"📝  Shimmie Mode:    {'Yes' if opts.shimmie else 'No'}")
    print(f"🧹  No Prune:        {'Yes' if opts.no_prune else 'No'}")
    print()
    conn = None
    sqlite_path = Path(opts.input_cache) if opts.input_cache else Path("tools/posts_cache.db")
    conn = None
    if sqlite_path.exists():
        conn = sqlite3.connect(sqlite_path)
    else:
        print(f"[WARN] Cache file not found: {sqlite_path}")
    if sqlite_path.exists():
        conn = sqlite3.connect(sqlite_path)

    if not opts.image_or_images or opts.image_or_images.strip().upper() == "NO_INPUT":
        opts.image_or_images = input("Input Folder or Image: ").strip(' "')

    image_path = Path(opts.image_or_images.strip()).resolve()
    if not image_path.exists():
        raise FileNotFoundError(f"Path not found: {image_path}")

    images = [f for f in (image_path.rglob("*") if opts.subfolder else image_path.iterdir()) if f.suffix.lower() in ALLOWED_EXTS and f.is_file()] if image_path.is_dir() else [image_path]

    model_id = MODEL_REPO_MAP.get(opts.model)
    model: nn.Module = timm.create_model("hf-hub:" + model_id).eval().to(torch_device)
    model.load_state_dict(timm.models.load_state_dict_from_hf(model_id))
    print("Loading tag list...")
    try:
        csv_path = hf_hub_download(repo_id=model_id, filename="selected_tags.csv")
        df = pd.read_csv(csv_path, usecols=["name", "category"])
        labels = LabelData(
            names=df["name"].tolist(),
            rating=list(np.where(df["category"] == 9)[0]),
            general=list(np.where(df["category"] == 0)[0]),
            character=list(np.where(df["category"] == 4)[0]),
            artist=list(np.where(df["category"] == 1)[0]),
            copyright=list(np.where(df["category"] == 3)[0]),
        )
    except HfHubHTTPError as e:
        raise FileNotFoundError(f"selected_tags.csv failed to download from {model_id}") from e


    transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))
    group_tree: GroupTree = load_groups()

    # Step 1: Load cache if present
    if conn:
        print("[INFO] Using SQLite cache from posts_cache.db...")
    else:
        print("[WARN] No SQLite cache found. Falling back entirely on tagger.")

    csv_rows = []

    # Create batches using the --batch_size option
    batches = [images[i:i + opts.batch_size] for i in range(0, len(images), opts.batch_size)]

    character_series_map = {}

    mapping_csv = Path("danbooru_character_webui.csv")
    if mapping_csv.exists():
        import csv
        with mapping_csv.open("r", encoding="utf-8") as f:
            reader = csv.reader(f)
            next(reader, None)  # skip header
            for row in reader:
                if len(row) >= 2:
                    char, series = row[0].strip(), row[1].strip()
                    if char and series:
                        character_series_map[char] = series
        print(f"[INFO] Loaded {len(character_series_map):,} character→series mappings.")
    else:
        print("[WARN] danbooru_character_webui.csv not found.")

    for batch in tqdm.tqdm(batches, desc="Tagging images"):

        # Preprocess and store md5s and images
        # === Multi-threaded post resolution ===
        with ThreadPoolExecutor(max_workers=opts.threads) as executor:
            results = list(tqdm.tqdm(
                executor.map(lambda img: resolve_post(img, sqlite_path), batch),
                total=len(batch),
                desc="Resolving posts"
            ))

        # Get images that need tagging
        tag_needed = [img for img, post in results if post is None]
        img_inputs = process_batch(tag_needed, transform)

        if img_inputs is not None and len(img_inputs) > 0:
            with torch.inference_mode():
                batched_tensor = img_inputs.to(torch_device)
                raw_outputs = F.sigmoid(model(batched_tensor)).cpu()
            raw_outputs = list(torch.unbind(raw_outputs, dim=0))
        else:
            raw_outputs = []

        out_idx = 0
        for image, post in results:
            # If post is still missing, run the tagger
            if not post:
                if out_idx >= len(img_inputs):
                    print(f"[WARN] Out-of-bounds image tensor for: {image.name}")
                    continue
                img_tensor = img_inputs[out_idx]
                if img_tensor is None:
                    continue  # skip if failed to load
                probs = raw_outputs[out_idx]
                out_idx += 1

                char, gen, artist, series, rating = get_tags(
                    probs,
                    labels,
                    opts.gen_threshold,
                    opts.char_threshold,
                    opts.rating_threshold
                )

                rating_letter = "?"
                if "explicit" in rating:
                    rating_letter = "e"
                elif "questionable" in rating or "sensitive" in rating:
                    rating_letter = "q"
                elif "general" in rating:
                    rating_letter = "s"

                post = {
                    "character": [t[0] for t in char.items()],
                    "general": [t[0] for t in gen.items()],
                    "artist": [t[0] for t in artist.items()],
                    "series": [t[0] for t in series.items()],
                    "rating": rating_letter,
                    "source": None
                }
                character_tags = [t[0] for t in char.items()]
                series_tags = set()

                for char_tag in character_tags:
                    if char_tag in character_series_map:
                        inferred_series = character_series_map[char_tag]
                        series_tags.add(inferred_series)

                # ✅ Append inferred series to post
                post["series"].extend(sorted(series_tags))

            # Build tags from post
            tags = []
            tags.extend(post.get("general", []))
            tags.extend(f"character:{t}" for t in post.get("character", []))
            tags.extend(f"series:{t}" for t in post.get("series", []))
            tags.extend(f"artist:{t}" for t in post.get("artist", []))

            # Clean rating-related tags and append a single normalized one
            tags = [t for t in tags if t not in ("general", "sensitive", "questionable", "explicit")]
            tags = [t for t in tags if not t.startswith("rating=")]

            rating_letter = post.get("rating", "?")
            tags.append(f"rating={rating_letter}")

            if post.get("source"):
                tags.append(f"source:{post['source']}")

            tags = sorted(set(tags))
            tag_str = ", ".join(tags)

            if opts.shimmie:
                rel_path = image.relative_to(image_path)
                csv_rows.append([
                    f"import/{rel_path}",
                    tag_str,
                    "",
                    rating_letter,
                    ""
                ])
    print(f"[✓] Ran tagger on {out_idx} of {len(images)} images.")

    if opts.shimmie and csv_rows:
        csv_path = image_path / "import.csv"
        with csv_path.open("w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f, quoting=csv.QUOTE_ALL)
            writer.writerows(csv_rows)
        print(f"[✓] Shimmie CSV written to {csv_path}")

    if conn:
        print("[✓] Done.")
        conn.close()
    print(f"\n[✓] Processed {len(images)} image(s) across {len(batches)} batch(es).")

if __name__ == "__main__":
    opts, _ = parse_known_args(ScriptOptions)
    main(opts)
